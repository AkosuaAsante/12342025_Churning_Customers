# -*- coding: utf-8 -*-
"""12342025_Churning_Customers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EM8RobQNDM0JPVMRUtQfmzQuUiyLfC2h
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.model_selection import train_test_split
csv_file_path = '/content/drive/MyDrive/Colab Notebooks/CustomerChurn_dataset.csv'
df = pd.read_csv(csv_file_path)
pd.set_option('display.max_columns', None)
import seaborn as sns
import matplotlib.pyplot as plt

df.head()

df2=df.copy()

from sklearn.preprocessing import LabelEncoder

feature=['MonthlyCharges','TotalCharges','OnlineSecurity','tenure','Contract','PaymentMethod']

le_OnlineSecurity=LabelEncoder()
df2['OnlineSecurity']=le_OnlineSecurity.fit_transform(df2['OnlineSecurity'])

le_contract=LabelEncoder()
df2['Contract']=le_contract.fit_transform(df2['Contract'])

le_payment=LabelEncoder()
df2['PaymentMethod']=le_contract.fit_transform(df2['PaymentMethod'])

df.info()

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

df.info()

mean = df['TotalCharges'].mean()
df['TotalCharges'].fillna(mean, inplace=True)

df.info()

print(df.isnull().sum())

customer_id=df.drop("customerID",axis=1,inplace=True)

valuessenior_citizen = df['SeniorCitizen'].unique()
valuessenior_citizen

sns.countplot(x='Churn', data=df)
plt.show()

categorical_features = df.select_dtypes(include=['object'])
for feature in categorical_features:
    plt.figure(figsize=(10, 4))
    sns.countplot(x=feature, hue='Churn', data=df)
    plt.title(f'Churn by {feature}')
    plt.xticks(rotation=45)
    plt.show()

numerical_features = df.select_dtypes(exclude=['object'])
for feature in numerical_features:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x='Churn', y=feature, data=df)
    plt.title(f'{feature} by Churn')
    plt.show()

"""

```
# This is formatted as code
```

*Feature* *Selection*"""

Churn=categorical_features.drop('Churn',axis=1,inplace=True)

data=df.copy()

data

data['Churn'],a=pd.factorize(data['Churn'])

data

y=data['Churn']

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()

for columns in numerical_features:
  data[columns]=sc.fit_transform(data[[columns]])

for column in categorical_features:
    data[column], _ = pd.factorize(data[column])

data

X=data.drop('Churn',axis=1)

Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)

from sklearn.tree import DecisionTreeClassifier

dtree=DecisionTreeClassifier()

dtree.fit(Xtrain,Ytrain)

from sklearn.metrics import accuracy_score,f1_score

y_pred=dtree.predict(Xtest)

accuracy_score(y_pred,Ytest)

importance = dtree.feature_importances_

feature_importance = pd.DataFrame({'Feature':X.columns, 'Importance': importance})
feature_importance = feature_importance.sort_values(by='Importance', ascending=False)
feature_importance

from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFECV
#Using RFECV
model = RandomForestClassifier(n_estimators=100, random_state=42)
rfecv = RFECV(estimator=model, step=1, cv=4, scoring='accuracy')
rfecv.fit(Xtrain, Ytrain)
selected_features = Xtrain.columns[rfecv.support_]
optimal_num_features = rfecv.n_features_
support_mask = rfecv.support_
selected_features = X.columns[support_mask]

selected_features

selectedfeature=['MonthlyCharges','TotalCharges','OnlineSecurity','tenure','Contract','PaymentMethod']

"""Building The Model"""

import keras
from keras.models import Model
from keras.layers import Input, Dense
from keras.optimizers import Adam
from keras.utils import to_categorical

y=data['Churn']
X=data[selectedfeature]

for i in selectedfeature:
 unique_values = df[i].unique()
 print(unique_values)

X.info()

Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)

Xtrain.info()

Xtrain,Xval,Ytrain,Yval = train_test_split(Xtrain, Ytrain, test_size=0.10, random_state=42, stratify=Ytrain)

# Keras Functional API model
input_layer = Input(shape=(Xtrain.shape[1],))
hidden_layer_1 = Dense(32, activation='relu')(input_layer)
hidden_layer_2 = Dense(24, activation='relu')(hidden_layer_1)
hidden_layer_3 = Dense(12, activation='relu')(hidden_layer_2)
hidden_layer_4 = Dense(12, activation='relu')(hidden_layer_3)
output_layer = Dense(1, activation='sigmoid')(hidden_layer_4)

model = Model(inputs=input_layer, outputs=output_layer)

model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

model.fit(Xtrain, Ytrain, epochs=600, batch_size=32, validation_data=(Xval, Yval))

_, accuracy = model.evaluate(Xtrain, Ytrain)
accuracy*100

loss, accuracy = model.evaluate(Xtest, Ytest)
print(f'Test Loss: {loss:.4f}')
print(f'Test Accuracy: {accuracy*100:.4f}')

from sklearn.metrics import accuracy_score
from sklearn import metrics

num_classes=1
epochs=68
batch_size=50

!pip install scikeras
!pip install tensorflow

import tensorflow as tf
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import Dense,Input,Dropout
from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import StratifiedKFold
from tensorflow.keras.constraints import MaxNorm
from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer, roc_auc_score

def create_model(neurons=64, dropout_rate=0.2, activation='relu'):
    inputs = Input(shape=(X.shape[1],))
    x = Dense(neurons, activation=activation)(inputs)
    x = Dropout(dropout_rate)(x)
    x = Dense(neurons, activation=activation)(x)
    x = Dropout(dropout_rate)(x)
    outputs = Dense(1, activation='sigmoid')(x)
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

"""*Cross* *Validation*


"""

model = KerasClassifier(model=create_model
                        ,epochs=epochs,
                        batch_size=batch_size,
                        activation='relu',
                        neurons=34,
                        dropout_rate=0.5
                        )

param_grid = {
    'neurons': [32,64,50],
    'dropout_rate': [0.2, 0.3,0.5],
    'activation': ['relu'],
    'optimizer': ['adam', 'rmsprop']


}

outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv, scoring='accuracy')

outer_scores = []
best_models = []

for train_idx, val_idx in outer_cv.split(Xtrain, Ytrain):
    Xtrain_outer, Xval_outer = Xtrain.iloc[train_idx], Xtrain.iloc[val_idx]
    ytrain_outer, yval_outer = Ytrain.iloc[train_idx], Ytrain.iloc[val_idx]

grid_search.fit(Xtrain_outer, ytrain_outer)
best_model = grid_search.best_estimator_
best_models.append(best_model)
models=grid_search.best_estimator_

models=grid_search.best_estimator_

y_pred_outer = models.predict(Xval_outer)
accuracy = accuracy_score(yval_outer, y_pred_outer)
outer_scores.append(accuracy)
from sklearn.metrics import classification_report

import numpy as np

print("Outer CV Scores:", outer_scores)
print("Mean Accuracy:", np.mean(outer_scores))
print("Standard Deviation:", np.std(outer_scores))

best_model = grid_search.best_estimator_
print("The best estimator:",grid_search.best_estimator_, "\n")
best_model.fit(Xtrain, Ytrain,epochs=epochs, batch_size=batch_size, verbose=0)

y_pred = best_model.predict(Xtest)

from sklearn.metrics import roc_curve, roc_auc_score, classification_report

y_pred = best_model.predict(Xtest)
fpr_mlp, tpr_mlp, _ = roc_curve(Ytest, y_pred)
auc_mlp = roc_auc_score(Ytest, y_pred)
print("AUC:", auc_mlp)

y_pred = np.round(y_pred).ravel()
print("\nClassification Report:\n", classification_report(Ytest, y_pred))

bestmodel=models

import pickle

#datas={"model":bestmodel,"le_OnlineSecurity":le_OnlineSecurity,"le_contract":le_contract,"le_payment":le_contract}

filename = '/content/drive/My Drive/Colab Notebooks/telmomodel.pkl'

with open(filename,'wb') as file:
  pickle.dump(bestmodel,file)